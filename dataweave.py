# -*- coding: utf-8 -*-
"""DataWeave.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BMt5h_XiADwiVX08_DyJN1upDZhvP70i
"""

import json
from config import yesterday_data_path, today_data_path


def json_converter(file_path):
    with open(file_path, "r") as f:
        data = f.read()
    data = data.replace("}", "},")
    data = data.replace("\n", "")

    data = data[:-1]
    data = "[" + data + "]"
    new_data = json.loads(data)
    return new_data


"""# 1. Number of URLH which are overlapping (Common) in two files."""


def urlh_overlapping(today_data, yesterday_data):
    today_data_urlh = [i["urlh"] for i in today_data]
    yesterday_data_urlh = [i["urlh"] for i in yesterday_data]
    common_urlh = list(set(today_data_urlh) & set(yesterday_data_urlh))
    print(
        f"Number of URLH which are overlapping (Common) in two files: {len(common_urlh)}"
    )


"""# 2. For all the URLH which are overlapping, calculate the price difference (wrt available_price) if there is any between yesterday's and today's crawls (scraped data). There might be duplicate URLHs in which case you can choose the first valid (with http_status 200) record.

# 3. Number of Unique categories in both files.
"""


def uniqueCategory(today_data, yesterday_data):
    # todays data
    today_data_urlh = [i["category"] for i in today_data]
    unique_category_list = set(today_data_urlh)
    unique_category_today = len(unique_category_list)
    print(f"Number of Unique categories in todays files is : {unique_category_today}")

    # yesterday data
    yesterday_data_urlh = [i["category"] for i in yesterday_data]
    unique_category_list = set(yesterday_data_urlh)
    unique_category_yesterday = len(unique_category_list)
    print(
        f"Number of Unique categories in yesterday's files is : {unique_category_yesterday}"
    )


"""# 4. Display List of categories which is not overlapping (Common) from two given files."""


def nonUniqueCategory(today_data, yesterday_data):
    today_data_category = [i["category"] for i in today_data]
    yesterday_data_category = [i["category"] for i in yesterday_data]
    not_common_category = list(set(today_data_category) ^ set(yesterday_data_category))
    if not not_common_category:
        print(
            "There is no category which is not overlapping (Common) from two given files"
        )
    print(not_common_category)


"""* None of the categories is non-common from two given files.

# 5. Generate the stats with count of urlh for all taxonomies (taxonomy is concatenation of category and subcategory separated by " > ") for today's file.
Eg:

Cat1 > Subcat1: 3500\
Cat1 > Subcat2: 2000\
Cat2 > Subcat3: 8900
"""


def taxonomies(today_data):
    tmp_dict = {}
    for i in today_data:
        key = i["category"] + " > " + i["subcategory"]
        if key not in tmp_dict:
            tmp_dict[key] = 1
        else:
            tmp_dict[key] += 1
    print(tmp_dict)


"""# 6. Generate a new file where mrp is normalized. If there is a 0 or a non-float value or the key doesn't exist, make it "NA"."""


def mrp_normalized(file_path):
    data = json_converter(file_path)
    today_final_list = []
    for i in data:
        if "mrp" in i and i["mrp"] != None:
            if i["mrp"] == "0" or i["mrp"].isdigit():
                i["mrp"] = "NA"
        else:
            i["mrp"] = "NA"
        today_final_list.append(i)

    # generate json file where the output will be stored
    out_file = open(f"{file_path}_normalized.json", "w")
    json.dump(today_final_list, out_file, indent=6)
    out_file.close()


# # read the generated file
# with open('/content/yesterday (1).json_normalized.json') as f:
#   data = json.load(f)

# data[:10]

"""# 7. Display the title and price of 10 items having least price.
Eg:\
Title1 --> its price\
Title2 --> its price\
upto 10
"""


def tenIteamLeastPrice(data):
    remove_none = [i for i in data if i["available_price"] != None]
    sorted_list = sorted(remove_none, key=lambda x: float(x["available_price"]))
    print(sorted_list[:10])


"""# 8. Display the top 5 subcategory having highest items."""


def fiveSubcatHighIteams(data):
    temp_dict = {}

    for i in data:
        if i["subcategory"] not in temp_dict:
            temp_dict[i["subcategory"]] = 1
        else:
            temp_dict[i["subcategory"]] += 1

    sorted_subcat = sorted(temp_dict.items(), key=lambda item: item[1])
    print(sorted_subcat[-5:])


"""# 9. Display stats of how many items have failed status (http_status other than 200 is to be considered as failure).
Eg.\
http_status        count\
500                23\
404                12

"""


def failedStatusItems(data):
    temp_dict = {}

    for i in data:
        if i["http_status"] != "200":
            if i["http_status"] not in temp_dict:
                temp_dict[i["http_status"]] = 1
            else:
                temp_dict[i["http_status"]] += 1
    for stats in temp_dict:
        print(f"http_status {stats} \ncount     {temp_dict[stats]}")
        print("*" * 10)


if __name__ == "__main__":

    yesterday_data = json_converter(yesterday_data_path)
    today_data = json_converter(today_data_path)
    print("\nAns: 1")
    urlh_overlapping(today_data, yesterday_data)
    print("\nAns: 3")
    uniqueCategory(today_data, yesterday_data)
    print("\nAns: 4")
    nonUniqueCategory(today_data, yesterday_data)
    print("\nAns: 5")
    taxonomies(today_data)
    print("\nAns: 6")
    mrp_normalized(yesterday_data_path)
    print("\nAns: 7")
    tenIteamLeastPrice(today_data)
    print("\nAns: 8")
    fiveSubcatHighIteams(today_data)

    print("\nAns: 9")
    failedStatusItems(today_data)
    failedStatusItems(yesterday_data)
